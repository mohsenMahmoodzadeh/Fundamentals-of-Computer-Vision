{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage import data, img_as_float\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Color Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.1 Convert Pepper to HSI format, and display the HIS components as separate grayscale images. Observe these images to comment on what does each of the H, S, I components represent. The HSI images should be saved in double precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    src = cv.imread(filename='../Images/5/Pepper.bmp')\n",
    "    rgb = np.float64(src) / 255.0\n",
    "\n",
    "    blue = rgb[:, :, 0]\n",
    "    green = rgb[:, :, 1]\n",
    "    red = rgb[:, :, 2]\n",
    "\n",
    "    intensity = (red + green + blue) / 3.0\n",
    "    normalized_intensity = np.zeros_like(a=intensity)\n",
    "    cv.normalize(src=intensity, dst=normalized_intensity, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "\n",
    "    saturation = 1.0 - 3.0 * np.minimum(np.minimum(red, green), blue) / (red + green + blue+0.0001)\n",
    "    normalized_saturation = np.zeros_like(a=saturation)\n",
    "    cv.normalize(src=saturation, dst=normalized_saturation, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "\n",
    "    hue = np.zeros_like(a=blue)\n",
    "    blue_height, blue_width = blue.shape\n",
    "    for x in range(blue_height):\n",
    "        for y in range(blue_width):\n",
    "            arg = 0.5 * ((red[x, y] - green[x, y]) + (red[x, y] - blue[x, y])) / math.sqrt(\n",
    "                (red[x, y] - green[x, y]) **2 + (red[x, y] - blue[x, y]) * (green[x, y] - blue[x, y]))\n",
    "            theta = math.acos(arg)\n",
    "\n",
    "            if blue[x, y] > green[x, y]:\n",
    "                hue[x, y] = 2.0 * math.pi - theta\n",
    "            else:\n",
    "                hue[x, y] = theta\n",
    "    hue /= (2.0 * math.pi)\n",
    "    normalized_hue = np.zeros_like(a=hue)\n",
    "    cv.normalize(src=hue, dst=normalized_hue, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "\n",
    "    normalized_hsi = np.zeros_like(src)\n",
    "    hsi = cv.merge((hue, normalized_saturation, normalized_intensity))\n",
    "    cv.normalize(src=hsi, dst=normalized_hsi, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "    cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.1 Implement uniform quantization of a color image. Your program should do the following:\n",
    "    1. Read a grayscale image into an array.\n",
    "    2. Quantize and save the quantized image in a different array.\n",
    "    3. Compute the MSE and PSNR between the original and quantized images.\n",
    "    4. Display and print the quantized image.\n",
    "Notice, your program should assume the input values are in the range of (0,256), but allow you to vary the reconstruction level. Record the MSE and PSNR obtained with ùêø=64,32,16,8 and display the quantized images with corresponding ùêø values. Comment on the image quality as you vary ùêø. (Test on Pepper Image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(A, B):\n",
    "    _img = np.float64(np.copy(A))\n",
    "    _ref = np.float64(np.copy(B))\n",
    "    mse = np.mean((_img - _ref) ** 2)\n",
    "    return mse\n",
    "\n",
    "def psnr(img, ref):\n",
    "    _img = np.float64(np.copy(img))\n",
    "    _ref = np.float64(np.copy(ref))\n",
    "\n",
    "    mse = np.mean((_img - _ref) ** 2)\n",
    "\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "def uniform_quantize(img,L):\n",
    "    height, width = img.shape\n",
    "    D = 256\n",
    "    Q = np.zeros(shape=(256, 1))\n",
    "    q = D/L\n",
    "    for i in range(256):\n",
    "        Q[i, 0] = math.floor(i/q) * q + q/2\n",
    "    out = np.zeros_like(img)\n",
    "    for x in range(height):\n",
    "        for y in range(width):\n",
    "            out[x, y] = Q[img[x, y], 0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv.imread(filename='../Images/5/Pepper.bmp')\n",
    "blue = src[:, :, 0]\n",
    "green = src[:, :, 1]\n",
    "red = src[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse(original, 64)=  1.6203460693359375\n",
      "psnr(original, 64)=  46.03472580922875\n"
     ]
    }
   ],
   "source": [
    "blue64 = uniform_quantize(img=blue, L=64)\n",
    "green64 = uniform_quantize(img=green, L=64)\n",
    "red64 = uniform_quantize(img=red, L=64)\n",
    "quan64 = cv.merge((blue64, green64, red64))\n",
    "# cv.imwrite(filename='../result_img/quan64.png', img=quan64)\n",
    "print('mse(original, 64)= ', mse(A=src,B=quan64))\n",
    "print('psnr(original, 64)= ', psnr(img=src, ref=quan64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse(original, 32)=  5.9712677001953125\n",
      "psnr(original, 32)=  40.370138192269906\n"
     ]
    }
   ],
   "source": [
    "blue32 = uniform_quantize(img=blue, L=32)\n",
    "green32 = uniform_quantize(img=green, L=32)\n",
    "red32 = uniform_quantize(img=red, L=32)\n",
    "quan32 = cv.merge((blue32, green32, red32))\n",
    "# cv.imwrite(filename='../result_img/quan32.png', img=quan32)\n",
    "print('mse(original, 32)= ', mse(A=src,B=quan32))\n",
    "print('psnr(original, 32)= ', psnr(img=src, ref=quan32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse(original, 16)=  23.099868774414062\n",
      "psnr(original, 16)=  34.49470848106058\n"
     ]
    }
   ],
   "source": [
    "blue16 = uniform_quantize(img=blue, L=16)\n",
    "green16 = uniform_quantize(img=green, L=16)\n",
    "red16 = uniform_quantize(img=red, L=16)\n",
    "quan16 = cv.merge((blue16, green16, red16))\n",
    "# cv.imwrite(filename='../result_img/quan16.png', img=quan16)\n",
    "print('mse(original, 16)= ', mse(A=src,B=quan16))\n",
    "print('psnr(original, 16)= ', psnr(img=src, ref=quan16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse(original, 8)=  88.61748758951823\n",
      "psnr(original, 8)=  28.655609277594955\n"
     ]
    }
   ],
   "source": [
    "blue8 = uniform_quantize(img=blue, L=8)\n",
    "green8 = uniform_quantize(img=green, L=8)\n",
    "red8 = uniform_quantize(img=red, L=8)\n",
    "quan8 = cv.merge((blue8, green8, red8))\n",
    "# cv.imwrite(filename='../result_img/quan8.png', img=quan8)\n",
    "print('mse(original, 8)= ', mse(A=src,B=quan8))\n",
    "print('psnr(original, 8)= ', psnr(img=src, ref=quan8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.2 For the Pepper image, quantize the R, G, and B components to 3, 3, and 2 bits, respectively, using a uniform quantizer. Display the original and quantized color image. Comment on the difference in color accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse(original, 488)=  165.71184794108072\n",
      "psnr(original, 488)=  25.937268004782386\n"
     ]
    }
   ],
   "source": [
    "blue4 = uniform_quantize(img=blue, L=4)\n",
    "green8 = uniform_quantize(img=green, L=8)\n",
    "red8 = uniform_quantize(img=red, L=8)\n",
    "quan488 = cv.merge((blue4, green8, red8))\n",
    "# cv.imwrite(filename='../result_img/quan488.png', img=quan488)\n",
    "print('mse(original, 488)= ', mse(A=src,B=quan488))\n",
    "print('psnr(original, 488)= ', psnr(img=src, ref=quan488))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.3 We want to weave the Girl image on a rug. To do so, we need to reduce the number of colors in the image with minimal visual quality loss. If we can have 32, 16 and 8 different colors in the weaving process, reduce the color of the image to these three special modes. Discuss and display the results.\n",
    "Note: you can use immse and psnr for problem 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_color_quantize(img, clusters=8, rounds=1):\n",
    "    h, w = img.shape[:2]\n",
    "    samples = np.zeros([h*w,3], dtype=np.float32)\n",
    "    count = 0\n",
    "\n",
    "    for x in range(h):\n",
    "        for y in range(w):\n",
    "            samples[count] = img[x][y]\n",
    "            count += 1\n",
    "\n",
    "    compactness, labels, centers = cv.kmeans(samples,\n",
    "            clusters, \n",
    "            None,\n",
    "            (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10000, 0.0001), \n",
    "            rounds, \n",
    "            cv.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    centers = np.uint8(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    return res.reshape((img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssim(original, 8)=  0.6974988084823495\n",
      "ssim(original, 16)=  0.759914310402381\n",
      "ssim(original, 32)=  0.8337052139182909\n"
     ]
    }
   ],
   "source": [
    "src = cv.imread('../Images/5/Girl.bmp')\n",
    "girl8 = kmeans_color_quantize(img=src, clusters=8)\n",
    "girl16 = kmeans_color_quantize(img=src, clusters=16)\n",
    "girl32 = kmeans_color_quantize(img=src, clusters=32)\n",
    "\n",
    "print('ssim(original, 8)= ', ssim(src, girl8, multichannel=True))\n",
    "print('ssim(original, 16)= ', ssim(src, girl16, multichannel=True))\n",
    "print('ssim(original, 32)= ', ssim(src, girl32, multichannel=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
